{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df_ip = pd.DataFrame()\n",
    "plot_df_caller = pd.DataFrame()\n",
    "\n",
    "global rep\n",
    "global df\n",
    "\n",
    "def open_file_nf_6pro_3ch_rasp_ff(file_name):\n",
    "    \"\"\"\n",
    "    Reads a CSV file for reels video experiment with the new format.\n",
    "    Calculates energy consumption for video watching sessions using both original and optimized methods.\n",
    "    \n",
    "    New format includes:\n",
    "    - Proper datetime timestamps\n",
    "    - Pre-calculated accumulated energy (acc_BAT_Wh, acc_BB_Wh, acc_PA_Wh)\n",
    "    - acc_samples_total instead of count\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with timestamps, SPS, and energy data.\n",
    "        float: Mean SPS.\n",
    "        float: Count-based mean SPS.\n",
    "        float: Log duration in seconds.\n",
    "        dict: Energy calculations (original method).\n",
    "        dict: Energy calculations (optimized method).\n",
    "    \"\"\"\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Parse the combined voltage/current/power column\n",
    "    power_data = df['V_BAT,I_BAT,P_BAT,V_BB,I_BB,P_BB,V_PA,I_PA,P_PA'].str.split(',', expand=True)\n",
    "    power_data.columns = ['V_BAT', 'I_BAT', 'P_BAT', 'V_BB', 'I_BB', 'P_BB', 'V_PA', 'I_PA', 'P_PA']\n",
    "    \n",
    "    # Convert to numeric\n",
    "    power_data = power_data.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Add parsed columns to dataframe\n",
    "    df = pd.concat([df, power_data], axis=1)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    # Calculate time differences in seconds\n",
    "    df['dt'] = df['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "    \n",
    "    # Calculate RF power (BB + PA)\n",
    "    df['P_RF'] = df['P_BB'] + df['P_PA']\n",
    "    \n",
    "    # =================== ORIGINAL METHOD (Trapezoidal Integration) ===================\n",
    "    # Initialize energy columns for original method\n",
    "    df['E_BAT_orig'] = 0.0\n",
    "    df['E_RF_orig'] = 0.0\n",
    "    df['E_PA_orig'] = 0.0\n",
    "    df['E_BB_orig'] = 0.0\n",
    "    \n",
    "    # Calculate cumulative energy using trapezoidal rule (original method)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.at[i, 'dt'] > 0:  # Only calculate if time difference is positive\n",
    "            # Battery energy\n",
    "            df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
    "                [df.at[i-1, 'P_BAT'], df.at[i, 'P_BAT']], \n",
    "                x=[0, df.at[i, 'dt']]\n",
    "            )\n",
    "            \n",
    "            # RF energy\n",
    "            df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
    "                [df.at[i-1, 'P_RF'], df.at[i, 'P_RF']], \n",
    "                x=[0, df.at[i, 'dt']]\n",
    "            )\n",
    "            \n",
    "            # PA energy\n",
    "            df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
    "                [df.at[i-1, 'P_PA'], df.at[i, 'P_PA']], \n",
    "                x=[0, df.at[i, 'dt']]\n",
    "            )\n",
    "            \n",
    "            # BB energy\n",
    "            df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n",
    "                [df.at[i-1, 'P_BB'], df.at[i, 'P_BB']], \n",
    "                x=[0, df.at[i, 'dt']]\n",
    "            )\n",
    "        else:\n",
    "            # Copy previous values if no time difference\n",
    "            df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig']\n",
    "            df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig']\n",
    "            df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig']\n",
    "            df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig']\n",
    "    \n",
    "    # =================== OPTIMIZED METHOD (Pre-calculated Values) ===================\n",
    "    # Convert accumulated energy from Wh to Joules (1 Wh = 3600 J)\n",
    "    # df['E_BAT_opt'] = df['acc_BAT_Wh'] * 3600\n",
    "    # df['E_BB_opt'] = df['acc_BB_Wh'] * 3600\n",
    "    # df['E_PA_opt'] = df['acc_PA_Wh'] * 3600\n",
    "    # df['E_RF_opt'] = (df['acc_BB_Wh'] + df['acc_PA_Wh']) * 3600\n",
    "    \n",
    "    # =================== SPS CALCULATIONS ===================\n",
    "    # Calculate SPS using sample count differences\n",
    "    df['sample_diff'] = df['acc_samples_total'].diff().fillna(0)\n",
    "    df['SPS'] = np.where(df['dt'] > 0, df['sample_diff'] / df['dt'], 0)\n",
    "    \n",
    "    # Calculate mean SPS (excluding zeros and invalid values)\n",
    "    valid_sps = df['SPS'][(df['SPS'] > 0) & (df['dt'] > 0)]\n",
    "    sps_mean = valid_sps.mean() if len(valid_sps) > 0 else 0\n",
    "    \n",
    "    # Alternative SPS calculation using time windows\n",
    "    df['time_second'] = df['Timestamp'].dt.floor('s')\n",
    "    sps_by_second = df.groupby('time_second')['sample_diff'].sum()\n",
    "    sps_count_mean = sps_by_second.mean() if len(sps_by_second) > 0 else 0\n",
    "    \n",
    "    # =================== TIME FORMATTING ===================\n",
    "    df['time_sec_abs'] = (df['Timestamp'] - df['Timestamp'].min()).dt.total_seconds()\n",
    "    df['minutes'], df['seconds'] = divmod(df['time_sec_abs'], 60)\n",
    "    df['seconds'], df['milliseconds'] = divmod(df['seconds'], 1)\n",
    "    df['milliseconds'] *= 1000\n",
    "    df['time_formated_abs'] = (df['minutes'].astype(int).astype(str).str.zfill(2) + ':' + \n",
    "                              df['seconds'].astype(int).astype(str).str.zfill(2) + '.' + \n",
    "                              df['milliseconds'].astype(int).astype(str).str.zfill(3))\n",
    "    \n",
    "    # Calculate log duration\n",
    "    log_duration = (df['Timestamp'].max() - df['Timestamp'].min()).total_seconds()\n",
    "    \n",
    "    # =================== VIDEO WATCHING PHASES ===================\n",
    "    # Process useful_data for video watching phases (if applicable)\n",
    "    if 'useful_data' in df.columns:\n",
    "        # Create groups based on useful_data changes (video watching periods)\n",
    "        df['video_session'] = (df['useful_data'].diff() != 0).cumsum()\n",
    "        df['is_watching'] = df['useful_data'] == 1\n",
    "    else:\n",
    "        # If no useful_data column, consider entire session as watching\n",
    "        df['video_session'] = 1\n",
    "        df['is_watching'] = True\n",
    "    \n",
    "    # =================== ENERGY CALCULATIONS FOR BOTH METHODS ===================\n",
    "    # Original method - total accumulated energy\n",
    "    energy_orig = {\n",
    "        'total_E_BAT': df['E_BAT_orig'].iloc[-1] if len(df) > 0 else 0,\n",
    "        'total_E_RF': df['E_RF_orig'].iloc[-1] if len(df) > 0 else 0,\n",
    "        'total_E_PA': df['E_PA_orig'].iloc[-1] if len(df) > 0 else 0,\n",
    "        'total_E_BB': df['E_BB_orig'].iloc[-1] if len(df) > 0 else 0\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    return df, sps_mean, sps_count_mean, log_duration, energy_orig\n",
    "\n",
    "\n",
    "def dataset_analyze_rasp_ff(file_name):\n",
    "    \"\"\"\n",
    "    Analyzes reels video experiment data and assembles results in a standardized table.\n",
    "    Supports both static and dynamic experiment conditions.\n",
    "    \n",
    "    Filename formats:\n",
    "    Static: exp_total_device_ran_platform_condition_sps.csv\n",
    "    Dynamic: exp_total_device_ran_platform_condition_path_from_to_sps.csv\n",
    "    \"\"\"\n",
    "    global result_df, section_df, duplicate_rows_result_df\n",
    "    \n",
    "    # Process the file\n",
    "    df, sps, sps_count, duration, energy_orig = open_file_nf_6pro_3ch_rasp_ff(file_name)\n",
    "    \n",
    "    section_df = df\n",
    "    \n",
    "    # Parse filename components\n",
    "    file_name_base = os.path.basename(file_name)\n",
    "    filename_parts = file_name_base.replace('.csv', '').split('_')\n",
    "    \n",
    "    # Extract basic experiment info\n",
    "    exp_number = filename_parts[0] if len(filename_parts) >= 1 else None\n",
    "    total_exp = filename_parts[1] if len(filename_parts) >= 2 else None\n",
    "    device = filename_parts[2] if len(filename_parts) >= 3 else None\n",
    "    ran_tech = filename_parts[3] if len(filename_parts) >= 4 else None\n",
    "    platform = filename_parts[4] if len(filename_parts) >= 5 else None\n",
    "    condition = filename_parts[5] if len(filename_parts) >= 6 else None\n",
    "    \n",
    "    # Handle dynamic vs static experiments\n",
    "    if condition and condition.lower() == 'dyna':\n",
    "        # Dynamic experiment: exp_total_device_ran_platform_dyna_path_from_to_sps\n",
    "        path = filename_parts[6] if len(filename_parts) >= 7 else None\n",
    "        from_location = filename_parts[7] if len(filename_parts) >= 8 else None\n",
    "        to_location = filename_parts[8] if len(filename_parts) >= 9 else None\n",
    "        sps_info = filename_parts[9] if len(filename_parts) >= 10 else None\n",
    "        experiment_type = \"Dynamic\"\n",
    "        location_info = f\"{from_location} to {to_location}\" if from_location and to_location else \"N/A\"\n",
    "        path_info = path if path else \"N/A\"\n",
    "    else:\n",
    "        # Static experiment: exp_total_device_ran_platform_stat_sps\n",
    "        sps_info = filename_parts[6] if len(filename_parts) >= 7 else None\n",
    "        experiment_type = \"Static\"\n",
    "        location_info = \"Fixed Location\"\n",
    "        path_info = \"N/A\"\n",
    "    \n",
    "    # Extract SPS value from sps_info (remove 'sps' suffix)\n",
    "    sps_value = sps_info.replace('sps', '') if sps_info else None\n",
    "    \n",
    "    # Calculate duration in minutes for energy per minute calculations\n",
    "    duration_minutes = duration / 60 if duration > 0 else 1  # Avoid division by zero\n",
    "    \n",
    "    # Helper function to safely format values\n",
    "    def safe_format(value, format_str='{:.2f}'):\n",
    "        return format_str.format(value) if not pd.isna(value) and value != 0 else '0.00'\n",
    "    \n",
    "    def safe_format_percent(value):\n",
    "        return '{:.2f}%'.format(value) if not pd.isna(value) else 'N/A'\n",
    "    \n",
    "    # Calculate percentages with safety checks\n",
    "    RF_percent_bat_orig = (energy_orig['total_E_RF'] / energy_orig['total_E_BAT'] * 100) if energy_orig['total_E_BAT'] != 0 else np.nan\n",
    "  \n",
    "    # Create result row\n",
    "    row = {\n",
    "        # Experiment Information\n",
    "        'File name': file_name_base,\n",
    "        'Exp Number': exp_number,\n",
    "        'Total Experiments': total_exp,\n",
    "        'Device': device,\n",
    "        'RAN Technology': ran_tech,\n",
    "        'Platform': platform,\n",
    "        'Condition': condition,\n",
    "        'Path': path_info,\n",
    "        'Location Route': location_info,\n",
    "        \n",
    "        # Energy per Minute - Original Method (Trapezoidal Integration)\n",
    "        'E_RF Jm': safe_format(energy_orig['total_E_RF'] / duration_minutes),\n",
    "        'E_BAT Jm': safe_format(energy_orig['total_E_BAT'] / duration_minutes),\n",
    "\n",
    "        'E_BB Jm': safe_format(energy_orig['total_E_BB'] / duration_minutes),\n",
    "        'E_PA Jm': safe_format(energy_orig['total_E_PA'] / duration_minutes),\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # Total Energy - Original Method\n",
    "        'Total E_RF J': safe_format(energy_orig['total_E_RF']),\n",
    "        'Total E_BAT J': safe_format(energy_orig['total_E_BAT']),\n",
    "\n",
    "        'Total E_PA J': safe_format(energy_orig['total_E_PA']),\n",
    "        'Total E_BB J': safe_format(energy_orig['total_E_BB']),\n",
    "        \n",
    "        # Percentages - Original Method\n",
    "        'E_RF % BAT': safe_format_percent(RF_percent_bat_orig),\n",
    "\n",
    "        \n",
    "\n",
    "        # Session Information\n",
    "        'Total Duration (sec)': safe_format(duration),\n",
    "        'Total Duration (min)': safe_format(duration_minutes),\n",
    "        'Measured SPS': '{:.5f}'.format(sps) if not pd.isna(sps) else '0.00000',\n",
    "        'SPS Count Method': '{:.5f}'.format(sps_count) if not pd.isna(sps_count) else '0.00000',\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Add to result dataframe\n",
    "    result_df = pd.concat([result_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    duplicate_rows_result_df = result_df[result_df.duplicated()]\n",
    "    \n",
    "    return duration, energy_orig, section_df, sps\n",
    "\n",
    "\n",
    "def apply_exponential_moving_average(data, span):\n",
    "    \"\"\"\n",
    "    Apply exponential moving average to smooth data.\n",
    "    \n",
    "    Args:\n",
    "        data: pandas Series or array-like data\n",
    "        span: int, span for the exponential moving average\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series: smoothed data\n",
    "    \"\"\"\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "# Initialize global variables if they don't exist\n",
    "try:\n",
    "    result_df\n",
    "except NameError:\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    section_df\n",
    "except NameError:\n",
    "    section_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    duplicate_rows_result_df\n",
    "except NameError:\n",
    "    duplicate_rows_result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_large_dataset(file_path, chunk_size=1000000, downsample_method='uniform', n_points=10000):\n",
    "    \"\"\"\n",
    "    Plot Reading vs Seconds from a large dataset by processing it in chunks and downsampling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the data file\n",
    "    chunk_size : int\n",
    "        Number of rows to read in each chunk\n",
    "    downsample_method : str\n",
    "        Method for downsampling: 'uniform', 'mean', or 'bin'\n",
    "    n_points : int\n",
    "        Target number of points to plot\n",
    "    \"\"\"\n",
    "    print(f\"Starting to process dataset: {Path(file_path).name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # First, determine the header structure and column names\n",
    "    print(\"Examining file structure...\")\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Read first few lines to analyze header\n",
    "        header_lines = [f.readline() for _ in range(20)]  # Read up to 20 lines to find header\n",
    "    \n",
    "    # Look for the line that seems to contain column names\n",
    "    header_row = None\n",
    "    for i, line in enumerate(header_lines):\n",
    "        if 'Index' in line and ('Second' in line or 'Time' in line):\n",
    "            header_row = i\n",
    "            print(f\"Found header at line {header_row}: {line.strip()}\")\n",
    "            header_content = line.strip()\n",
    "            break\n",
    "    \n",
    "    if header_row is None:\n",
    "        # If we couldn't find the header, assume it's the last non-empty line before data\n",
    "        for i in reversed(range(len(header_lines))):\n",
    "            if header_lines[i].strip():\n",
    "                header_row = i\n",
    "                header_content = header_lines[i].strip()\n",
    "                print(f\"Using line {header_row} as header: {header_content}\")\n",
    "                break\n",
    "    \n",
    "    # Determine column names from the header\n",
    "    columns = [col.strip() for col in header_content.split(',')]\n",
    "    print(f\"Detected columns: {columns}\")\n",
    "    \n",
    "    # Find appropriate column names for time and reading\n",
    "    time_col = None\n",
    "    reading_col = None\n",
    "    \n",
    "    # Look for time/seconds column\n",
    "    time_candidates = ['Seconds', 'Time', 'seconds', 'time']\n",
    "    for col in columns:\n",
    "        if col in time_candidates or any(tc in col for tc in time_candidates):\n",
    "            time_col = col\n",
    "            break\n",
    "    \n",
    "    # Look for reading column\n",
    "    reading_candidates = ['Reading', 'Value', 'reading', 'value', 'Data']\n",
    "    for col in columns:\n",
    "        if col in reading_candidates or any(rc in col for rc in reading_candidates):\n",
    "            reading_col = col\n",
    "            break\n",
    "    \n",
    "    # If we couldn't find matching columns, use Index (first column) and the second column\n",
    "    if time_col is None:\n",
    "        if 'Index' in columns:\n",
    "            time_col = 'Index'\n",
    "        else:\n",
    "            time_col = columns[0]\n",
    "        print(f\"Using '{time_col}' as time column\")\n",
    "    \n",
    "    if reading_col is None:\n",
    "        # Use the second column as reading if different from time column\n",
    "        for col in columns:\n",
    "            if col != time_col:\n",
    "                reading_col = col\n",
    "                break\n",
    "        if reading_col is None and len(columns) > 1:\n",
    "            reading_col = columns[1]\n",
    "        print(f\"Using '{reading_col}' as reading column\")\n",
    "    \n",
    "    print(f\"Selected columns: Time = '{time_col}', Reading = '{reading_col}'\")\n",
    "    \n",
    "    # First, let's find the min and max of time values to determine the range\n",
    "    min_seconds = float('inf')\n",
    "    max_seconds = float('-inf')\n",
    "    \n",
    "    print(\"Scanning file for time range...\")\n",
    "    chunks_read = 0\n",
    "    total_rows = 0\n",
    "    \n",
    "    # Read file in chunks to determine time range\n",
    "    for chunk in pd.read_csv(file_path, skiprows=header_row, chunksize=chunk_size, \n",
    "                            usecols=[time_col, reading_col]):\n",
    "        min_seconds = min(min_seconds, chunk[time_col].min())\n",
    "        max_seconds = max(max_seconds, chunk[time_col].max())\n",
    "        chunks_read += 1\n",
    "        total_rows += len(chunk)\n",
    "        print(f\"Scanned chunk {chunks_read}, total rows: {total_rows}\")\n",
    "    \n",
    "    print(f\"Time range: {min_seconds/60:.2f} to {max_seconds/60:.2f} minutes ({min_seconds:.2f} to {max_seconds:.2f} seconds)\")\n",
    "    \n",
    "    # For binning approach\n",
    "    if downsample_method == 'bin':\n",
    "        # Create bins for time ranges\n",
    "        num_bins = n_points\n",
    "        bin_edges = np.linspace(min_seconds, max_seconds, num_bins + 1)\n",
    "        bin_width = (max_seconds - min_seconds) / num_bins\n",
    "        \n",
    "        # Arrays to store results\n",
    "        bin_counts = np.zeros(num_bins)\n",
    "        bin_sums = np.zeros(num_bins)\n",
    "        \n",
    "        print(\"Processing chunks for binning...\")\n",
    "        chunks_read = 0\n",
    "        \n",
    "        # Bin centers for plotting - calculate here but use later\n",
    "        bin_centers = min_seconds + (np.arange(num_bins) + 0.5) * bin_width\n",
    "        \n",
    "        # Process each chunk\n",
    "        for chunk in pd.read_csv(file_path, skiprows=header_row, chunksize=chunk_size,\n",
    "                                usecols=[time_col, reading_col]):\n",
    "            # Assign each row to a bin\n",
    "            bin_indices = np.floor((chunk[time_col] - min_seconds) / bin_width).astype(int)\n",
    "            # Handle edge case\n",
    "            bin_indices = np.clip(bin_indices, 0, num_bins - 1)\n",
    "            \n",
    "            # Update bin counts and sums for this chunk\n",
    "            for i in range(num_bins):\n",
    "                mask = (bin_indices == i)\n",
    "                bin_counts[i] += mask.sum()\n",
    "                bin_sums[i] += chunk.loc[mask, reading_col].sum()\n",
    "            \n",
    "            chunks_read += 1\n",
    "            print(f\"Processed chunk {chunks_read} for binning\")\n",
    "        \n",
    "        # Calculate mean for each bin\n",
    "        bin_means = np.zeros(num_bins)\n",
    "        for i in range(num_bins):\n",
    "            if bin_counts[i] > 0:\n",
    "                bin_means[i] = bin_sums[i] / bin_counts[i]\n",
    "        \n",
    "        # Bin centers for plotting - convert to minutes\n",
    "        bin_centers_min = bin_centers / 60.0\n",
    "        \n",
    "        # Create Plotly figure\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers_min,\n",
    "            y=bin_means,\n",
    "            mode='lines',\n",
    "            line=dict(width=2),\n",
    "            name=f'{reading_col} (Binned Average)',\n",
    "            hovertemplate=f'<b>Time:</b> %{{x:.2f}} minutes<br><b>{reading_col}:</b> %{{y:.4f}}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'{reading_col} vs {time_col} - Binned Average ({n_points} bins)',\n",
    "            xaxis_title=f'Minutes',\n",
    "            yaxis_title=f'{reading_col} (Average)',\n",
    "            width=1200,\n",
    "            height=600,\n",
    "            showlegend=True,\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "        \n",
    "    elif downsample_method == 'uniform':\n",
    "        # Uniform sampling - take evenly spaced chunks\n",
    "        seconds_all = []\n",
    "        readings_all = []\n",
    "        \n",
    "        # Calculate how many rows to skip between samples\n",
    "        total_rows_estimate = 20000000  # From your header info\n",
    "        skip_factor = max(1, total_rows_estimate // n_points)\n",
    "        \n",
    "        print(f\"Using uniform sampling with skip factor: {skip_factor}\")\n",
    "        \n",
    "        # Read only the rows we need\n",
    "        sampled_data = pd.read_csv(file_path, skiprows=lambda x: x == 0 or (x > header_row and x % skip_factor != 0),\n",
    "                                  usecols=[time_col, reading_col])\n",
    "        \n",
    "        print(f\"Sampled {len(sampled_data)} points from dataset\")\n",
    "        \n",
    "        # Convert seconds to minutes for plotting\n",
    "        sampled_data['time_minutes'] = sampled_data[time_col] / 60.0\n",
    "        \n",
    "        # Create Plotly figure\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=sampled_data['time_minutes'],\n",
    "            y=sampled_data[reading_col],\n",
    "            mode='lines',\n",
    "            line=dict(width=1),\n",
    "            name=f'{reading_col} (Uniform Sample)',\n",
    "            hovertemplate=f'<b>Time:</b> %{{x:.2f}} minutes<br><b>{reading_col}:</b> %{{y:.4f}}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'{reading_col} vs {time_col} - Uniform Sampling (approx. {n_points} points)',\n",
    "            xaxis_title=f'{time_col} (minutes)',\n",
    "            yaxis_title=reading_col,\n",
    "            width=1200,\n",
    "            height=600,\n",
    "            showlegend=True,\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "    \n",
    "    elif downsample_method == 'mean':\n",
    "        # Determine the number of chunks to process\n",
    "        chunk_means = []\n",
    "        chunk_times = []\n",
    "        \n",
    "        print(\"Processing chunks for mean values...\")\n",
    "        chunks_read = 0\n",
    "        \n",
    "        # Process each chunk\n",
    "        for chunk in pd.read_csv(file_path, skiprows=header_row, chunksize=chunk_size,\n",
    "                                usecols=[time_col, reading_col]):\n",
    "            # Calculate mean for this chunk\n",
    "            mean_reading = chunk[reading_col].mean()\n",
    "            mean_time = chunk[time_col].mean()\n",
    "            \n",
    "            chunk_means.append(mean_reading)\n",
    "            chunk_times.append(mean_time)\n",
    "            \n",
    "            chunks_read += 1\n",
    "            print(f\"Processed chunk {chunks_read} for means\")\n",
    "        \n",
    "        # Convert seconds to minutes for plotting\n",
    "        chunk_times_min = [t / 60.0 for t in chunk_times]\n",
    "        \n",
    "        # Create Plotly figure\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=chunk_times_min,\n",
    "            y=chunk_means,\n",
    "            mode='lines+markers',\n",
    "            line=dict(width=2),\n",
    "            marker=dict(size=6),\n",
    "            name=f'{reading_col} (Chunk Averages)',\n",
    "            hovertemplate=f'<b>Time:</b> %{{x:.2f}} minutes<br><b>{reading_col}:</b> %{{y:.4f}}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'{reading_col} vs {time_col} - Chunk Averages ({chunks_read} chunks)',\n",
    "            xaxis_title=f'{time_col} (minutes)',\n",
    "            yaxis_title=f'{reading_col} (Average)',\n",
    "            width=1200,\n",
    "            height=600,\n",
    "            showlegend=True,\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Processing completed in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Save the plot as HTML (interactive) and optionally as PNG\n",
    "    output_file_html = f\"{reading_col}_vs_{time_col}_minutes_{downsample_method}.html\"\n",
    "    output_file_png = f\"{reading_col}_vs_{time_col}_minutes_{downsample_method}.png\"\n",
    "    \n",
    "    # Save as interactive HTML\n",
    "    fig.write_html(output_file_html)\n",
    "    print(f\"Interactive plot saved as {output_file_html}\")\n",
    "    \n",
    "    # Optionally save as PNG (requires kaleido: pip install kaleido)\n",
    "    try:\n",
    "        fig.write_image(output_file_png, width=1200, height=600, scale=2)\n",
    "        print(f\"Static plot saved as {output_file_png}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save PNG (install kaleido for PNG export): {e}\")\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    \n",
    "    return output_file_html, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1_5_6pro_LTE_tiktok_Dyna_T1_Belcombe_Auditorium_64sps.csv. passed. Count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_LTE_tiktok_Dyna_T1_Doua_Auditorium_64sps.csv. passed. Count: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_LTE_insta_Dyna_T1_Prefecture_INSA_64sps.csv. passed. Count: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_LTE_insta_stat_64sps.csv. passed. Count: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_5_6pro_LTE_insta_Dyna_T1_Prefecture_INSA_64sps.csv. passed. Count: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_5_6pro_LTE_tiktok_Dyna_T1_INSA_Prefecture_64sps.csv. passed. Count: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_3G_tiktok_stat_64sps.csv. passed. Count: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_5_6pro_3G_tiktok_stat_64sps.csv. passed. Count: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_3G_YTshorts_stat_64sps.csv. passed. Count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_3G_insta_stat_64sps.csv. passed. Count: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_3G_tiktok_stat_64sps.csv. passed. Count: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_LTE_insta_Dyna_T1_Prefecture_INSA_64sps.csv. passed. Count: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_LTE_YTshorts_stat_64sps.csv. passed. Count: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_LTE_tiktok_stat_64sps.csv. passed. Count: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_3G_YTshorts_stat_64sps.csv. passed. Count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_6pro_LTE_tiktok_Dyna_T1_INSA_Prefecture_64sps.csv. passed. Count: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_LTE_YTshorts_stat_64sps.csv. passed. Count: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_LTE_tiktok_stat_64sps.csv. passed. Count: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_LTE_insta_stat_64sps.csv. passed. Count: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_5_6pro_3G_insta_stat_64sps.csv. passed. Count: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter environments\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "unique_filenames = set()\n",
    "directory_path = './data/Experiment_Data/SIR_Experiment/Reels/'\n",
    "#directory_path = 'G:\\My Drive\\Phd\\Data\\Data files\\Experiment_Data\\SIR_Experiment\\Reels'\n",
    "file_list = [ \n",
    "    os.path.join(directory_path, filename) for filename in [\n",
    "            \"1_5_6pro_LTE_tiktok_Dyna_T1_Belcombe_Auditorium_64sps.csv\",\n",
    "            \"1_5_6pro_LTE_tiktok_Dyna_T1_Doua_Auditorium_64sps.csv\",\n",
    "            \"1_5_6pro_LTE_insta_Dyna_T1_Prefecture_INSA_64sps.csv\",\n",
    "            \"2_5_6pro_LTE_insta_stat_64sps.csv\",\n",
    "            \"3_5_6pro_LTE_insta_Dyna_T1_Prefecture_INSA_64sps.csv\",\n",
    "            \"3_5_6pro_LTE_tiktok_Dyna_T1_INSA_Prefecture_64sps.csv\",\n",
    "            \"2_5_6pro_3G_tiktok_stat_64sps.csv\",\n",
    "            \"3_5_6pro_3G_tiktok_stat_64sps.csv\",\n",
    "            \"1_5_6pro_3G_YTshorts_stat_64sps.csv\",\n",
    "            \"2_5_6pro_3G_insta_stat_64sps.csv\",\n",
    "            \"1_5_6pro_3G_tiktok_stat_64sps.csv\",\n",
    "            \"2_5_6pro_LTE_insta_Dyna_T1_Prefecture_INSA_64sps.csv\",\n",
    "            \"2_5_6pro_LTE_YTshorts_stat_64sps.csv\",\n",
    "            \"2_5_6pro_LTE_tiktok_stat_64sps.csv\",\n",
    "            \"2_5_6pro_3G_YTshorts_stat_64sps.csv\",\n",
    "            \"2_5_6pro_LTE_tiktok_Dyna_T1_INSA_Prefecture_64sps.csv\",\n",
    "            \"1_5_6pro_LTE_YTshorts_stat_64sps.csv\",\n",
    "            \"1_5_6pro_LTE_tiktok_stat_64sps.csv\",\n",
    "            \"1_5_6pro_LTE_insta_stat_64sps.csv\",\n",
    "            \"1_5_6pro_3G_insta_stat_64sps.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "files_passed = 0\n",
    "duplicates_count = 0\n",
    "problematic_files = []\n",
    "print(len(file_list))  # This will output 36\n",
    "for file_name in file_list:\n",
    "    files_passed += 1\n",
    "    print(f\"{os.path.basename(file_name)}. passed. Count: {files_passed}\")\n",
    "    dataset_analyze_rasp_ff(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:68: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BAT_orig'] = df.at[i-1, 'E_BAT_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:74: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_RF_orig'] = df.at[i-1, 'E_RF_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:80: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_PA_orig'] = df.at[i-1, 'E_PA_orig'] + np.trapz(\n",
      "/var/folders/gt/zm5jcrpj6x5fxkp1kx5vrns80000gn/T/ipykernel_34407/2107472292.py:86: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  df.at[i, 'E_BB_orig'] = df.at[i-1, 'E_BB_orig'] + np.trapz(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n",
      "Duration: 625.66 seconds (10.43 minutes)\n",
      "Data points: 39897\n",
      "SPS Mean: 1023.42\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     92\u001b[39m fig.for_each_trace(\u001b[38;5;28;01mlambda\u001b[39;00m t: t.update(name=\u001b[33m'\u001b[39m\u001b[33m<b>\u001b[39m\u001b[33m'\u001b[39m + t.name.replace(\u001b[33m'\u001b[39m\u001b[33m_smooth\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33m'\u001b[39m\u001b[33m</b>\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Show and save the plot\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m fig.write_html(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(file_name).replace(\u001b[33m'\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_power_plot.html\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/plotly/basedatatypes.py:3414\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3381\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3382\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3383\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3410\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3411\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3412\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/plotly/io/_renderers.py:425\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    421\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    422\u001b[39m     )\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    426\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    427\u001b[39m     )\n\u001b[32m    429\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    431\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import os\n",
    "\n",
    "# Your file path\n",
    "file_name = './data/Experiment_Data/SIR_Experiment/Reels/2_5_6pro_3G_YTshorts_stat_64sps.csv'\n",
    "\n",
    "# Load and process the data using the optimized function\n",
    "df1, sps_mean, sps_count_mean, duration, energy_org = open_file_nf_6pro_3ch_rasp_ff(file_name)\n",
    "\n",
    "print(f\"File loaded successfully!\")\n",
    "print(f\"Duration: {duration:.2f} seconds ({duration/60:.2f} minutes)\")\n",
    "print(f\"Data points: {len(df1)}\")\n",
    "print(f\"SPS Mean: {sps_mean:.2f}\")\n",
    "\n",
    "# P_RF is already calculated in the function, but let's ensure it's correct\n",
    "df1['P_RF'] = df1['P_BB'] + df1['P_PA']\n",
    "\n",
    "# Apply exponential moving average for smoothing\n",
    "with pd.option_context(\"mode.copy_on_write\", True):\n",
    "    df1['P_BAT_smooth'] = apply_exponential_moving_average(df1['P_BAT'], 30)\n",
    "    df1['P_BB_smooth'] = apply_exponential_moving_average(df1['P_BB'], 30)\n",
    "    df1['P_PA_smooth'] = apply_exponential_moving_average(df1['P_PA'], 30)\n",
    "    df1['P_RF_smooth'] = apply_exponential_moving_average(df1['P_RF'], 30)\n",
    "\n",
    "# Create time column for plotting (using time_sec_abs for better axis handling)\n",
    "df1['time_minutes'] = df1['time_sec_abs'] / 60\n",
    "\n",
    "# Plot 1: Main power consumption plot\n",
    "fig = px.line(df1, \n",
    "              x='time_minutes', \n",
    "              y=['P_BAT_smooth', 'P_BB_smooth', 'P_PA_smooth', 'P_RF_smooth'],\n",
    "              labels={\n",
    "                  'value': 'Power (W)', \n",
    "                  'time_minutes': 'Time (minutes)',\n",
    "                  'variable': 'Power Type'\n",
    "              },\n",
    "              color_discrete_sequence=['black', 'steelblue', 'red', 'green'],\n",
    "              height=600,\n",
    "              width=1500,\n",
    "              title=f'Power Consumption - {os.path.basename(file_name)}'\n",
    "              )\n",
    "\n",
    "# Add useful_data as secondary y-axis\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df1['time_minutes'],\n",
    "        y=df1['useful_data'],\n",
    "        mode='lines',\n",
    "        name='useful_data',\n",
    "        line=dict(color='orange', width=2),\n",
    "        yaxis='y2'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout with secondary y-axis\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title='<b>Time (minutes)</b>',\n",
    "        tickformat='.2f'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='<b>Power (W)</b>',\n",
    "        side='left'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='<b>Useful Data</b>',\n",
    "        side='right',\n",
    "        overlaying='y',\n",
    "        range=[0, 1.2]\n",
    "    ),\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    legend=dict(\n",
    "        x=0.770, \n",
    "        y=1.0, \n",
    "        traceorder=\"normal\",\n",
    "        bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(family=\"Times New Roman\", size=20, color=\"black\")\n",
    "    ),\n",
    "    font_family=\"Times New Roman\",\n",
    "    font_color=\"black\",\n",
    "    font_size=25\n",
    ")\n",
    "\n",
    "# Update range slider thickness\n",
    "fig.update_xaxes(rangeslider_thickness=0.03)\n",
    "\n",
    "# Make legend text bold\n",
    "fig.for_each_trace(lambda t: t.update(name='<b>' + t.name.replace('_smooth', '') + '</b>'))\n",
    "\n",
    "# Show and save the plot\n",
    "fig.show()\n",
    "fig.write_html(f\"{os.path.basename(file_name).replace('.csv', '_power_plot.html')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_path = \"./data/Experiment_Data/Call Test/iPX_CAll_Callee_RX_4G_DMM.csv\"  # Replace with your actual file path\n",
    "    \n",
    "#     # You can choose from: 'uniform', 'mean', or 'bin'\n",
    "# plot_method = 'bin'\n",
    "    \n",
    "#     # Call the function with your preferred method\n",
    "# output_file, figure = plot_large_dataset(file_path, downsample_method=plot_method, n_points=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>E_RF_Jm</th>\n",
       "      <th>E_BAT_Jm</th>\n",
       "      <th>E_BB_Jm</th>\n",
       "      <th>E_PA_Jm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6pro_3G_YTshorts_stat</td>\n",
       "      <td>54.495000</td>\n",
       "      <td>155.435</td>\n",
       "      <td>42.4300</td>\n",
       "      <td>12.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6pro_3G_insta_stat</td>\n",
       "      <td>48.990000</td>\n",
       "      <td>194.390</td>\n",
       "      <td>43.3100</td>\n",
       "      <td>5.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6pro_3G_tiktok_stat</td>\n",
       "      <td>53.016667</td>\n",
       "      <td>164.240</td>\n",
       "      <td>44.9900</td>\n",
       "      <td>8.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6pro_LTE_YTshorts_stat</td>\n",
       "      <td>68.085000</td>\n",
       "      <td>-2.520</td>\n",
       "      <td>49.1550</td>\n",
       "      <td>18.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6pro_LTE_insta_Dyna</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>191.860</td>\n",
       "      <td>47.5600</td>\n",
       "      <td>5.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6pro_LTE_insta_stat</td>\n",
       "      <td>72.800000</td>\n",
       "      <td>199.715</td>\n",
       "      <td>66.8500</td>\n",
       "      <td>5.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6pro_LTE_tiktok_Dyna</td>\n",
       "      <td>58.105000</td>\n",
       "      <td>176.050</td>\n",
       "      <td>50.0325</td>\n",
       "      <td>8.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6pro_LTE_tiktok_stat</td>\n",
       "      <td>57.080000</td>\n",
       "      <td>-33.500</td>\n",
       "      <td>44.7550</td>\n",
       "      <td>12.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              scenario_id    E_RF_Jm  E_BAT_Jm  E_BB_Jm    E_PA_Jm\n",
       "0   6pro_3G_YTshorts_stat  54.495000   155.435  42.4300  12.065000\n",
       "1      6pro_3G_insta_stat  48.990000   194.390  43.3100   5.675000\n",
       "2     6pro_3G_tiktok_stat  53.016667   164.240  44.9900   8.026667\n",
       "3  6pro_LTE_YTshorts_stat  68.085000    -2.520  49.1550  18.930000\n",
       "4     6pro_LTE_insta_Dyna  53.000000   191.860  47.5600   5.433333\n",
       "5     6pro_LTE_insta_stat  72.800000   199.715  66.8500   5.945000\n",
       "6    6pro_LTE_tiktok_Dyna  58.105000   176.050  50.0325   8.070000\n",
       "7    6pro_LTE_tiktok_stat  57.080000   -33.500  44.7550  12.325000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your result_df if not done already\n",
    "# result_df = pd.read_csv(\"result_df.csv\")\n",
    "\n",
    "# Add scenario_id column\n",
    "# Create scenario_id from the relevant columns\n",
    "result_df['scenario_id'] = (\n",
    "    result_df['Device'].astype(str).str.strip() + \"_\" +\n",
    "    result_df['RAN Technology'].astype(str).str.strip() + \"_\" +\n",
    "    result_df['Platform'].astype(str).str.strip() + \"_\" +\n",
    "    result_df['Condition'].astype(str).str.strip()\n",
    ")\n",
    "# Compute average energy values per scenario\n",
    "# Clean energy columns just in case\n",
    "energy_cols = ['E_RF Jm', 'E_BAT Jm', 'E_BB Jm', 'E_PA Jm']\n",
    "result_df[energy_cols] = result_df[energy_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Group by scenario_id\n",
    "scenario_summary_df = result_df.groupby('scenario_id')[energy_cols].mean().reset_index()\n",
    "\n",
    "# Optional: rename for clarity\n",
    "scenario_summary_df.columns = ['scenario_id', 'E_RF_Jm', 'E_BAT_Jm', 'E_BB_Jm', 'E_PA_Jm']\n",
    "\n",
    "# Save to CSV for frontend usage\n",
    "scenario_summary_df.to_csv(\"frontend_energy_summary.csv\", index=False)\n",
    "\n",
    "\n",
    "# Show preview in notebook\n",
    "scenario_summary_df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
